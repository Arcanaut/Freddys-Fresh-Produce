{"ast":null,"code":"import { __assign } from \"tslib\";\nimport { invariant, InvariantError } from \"../../utilities/globals/index.js\";\nimport { equal } from '@wry/equality';\nimport { Trie } from '@wry/trie';\nimport { createFragmentMap, getFragmentFromSelection, getDefaultValues, getFragmentDefinitions, getOperationDefinition, getTypenameFromResult, makeReference, isField, resultKeyNameFromField, isReference, shouldInclude, cloneDeep, addTypenameToDocument, isNonEmptyArray, argumentsObjectFromField } from \"../../utilities/index.js\";\nimport { makeProcessedFieldsMerger, fieldNameFromStoreName, storeValueIsStoreObject, isArray } from \"./helpers.js\";\nimport { canonicalStringify } from \"./object-canon.js\";\nimport { normalizeReadFieldOptions } from \"./policies.js\";\n;\n\nfunction getContextFlavor(context, clientOnly, deferred) {\n  var key = \"\".concat(clientOnly).concat(deferred);\n  var flavored = context.flavors.get(key);\n\n  if (!flavored) {\n    context.flavors.set(key, flavored = context.clientOnly === clientOnly && context.deferred === deferred ? context : __assign(__assign({}, context), {\n      clientOnly: clientOnly,\n      deferred: deferred\n    }));\n  }\n\n  return flavored;\n}\n\nvar StoreWriter = function () {\n  function StoreWriter(cache, reader) {\n    this.cache = cache;\n    this.reader = reader;\n  }\n\n  StoreWriter.prototype.writeToStore = function (store, _a) {\n    var _this = this;\n\n    var query = _a.query,\n        result = _a.result,\n        dataId = _a.dataId,\n        variables = _a.variables,\n        overwrite = _a.overwrite;\n    var operationDefinition = getOperationDefinition(query);\n    var merger = makeProcessedFieldsMerger();\n    variables = __assign(__assign({}, getDefaultValues(operationDefinition)), variables);\n    var context = {\n      store: store,\n      written: Object.create(null),\n      merge: function (existing, incoming) {\n        return merger.merge(existing, incoming);\n      },\n      variables: variables,\n      varString: canonicalStringify(variables),\n      fragmentMap: createFragmentMap(getFragmentDefinitions(query)),\n      overwrite: !!overwrite,\n      incomingById: new Map(),\n      clientOnly: false,\n      deferred: false,\n      flavors: new Map()\n    };\n    var ref = this.processSelectionSet({\n      result: result || Object.create(null),\n      dataId: dataId,\n      selectionSet: operationDefinition.selectionSet,\n      mergeTree: {\n        map: new Map()\n      },\n      context: context\n    });\n\n    if (!isReference(ref)) {\n      throw __DEV__ ? new InvariantError(\"Could not identify object \".concat(JSON.stringify(result))) : new InvariantError(6);\n    }\n\n    context.incomingById.forEach(function (_a, dataId) {\n      var storeObject = _a.storeObject,\n          mergeTree = _a.mergeTree,\n          fieldNodeSet = _a.fieldNodeSet;\n      var entityRef = makeReference(dataId);\n\n      if (mergeTree && mergeTree.map.size) {\n        var applied = _this.applyMerges(mergeTree, entityRef, storeObject, context);\n\n        if (isReference(applied)) {\n          return;\n        }\n\n        storeObject = applied;\n      }\n\n      if (__DEV__ && !context.overwrite) {\n        var fieldsWithSelectionSets_1 = Object.create(null);\n        fieldNodeSet.forEach(function (field) {\n          if (field.selectionSet) {\n            fieldsWithSelectionSets_1[field.name.value] = true;\n          }\n        });\n\n        var hasSelectionSet_1 = function (storeFieldName) {\n          return fieldsWithSelectionSets_1[fieldNameFromStoreName(storeFieldName)] === true;\n        };\n\n        var hasMergeFunction_1 = function (storeFieldName) {\n          var childTree = mergeTree && mergeTree.map.get(storeFieldName);\n          return Boolean(childTree && childTree.info && childTree.info.merge);\n        };\n\n        Object.keys(storeObject).forEach(function (storeFieldName) {\n          if (hasSelectionSet_1(storeFieldName) && !hasMergeFunction_1(storeFieldName)) {\n            warnAboutDataLoss(entityRef, storeObject, storeFieldName, context.store);\n          }\n        });\n      }\n\n      store.merge(dataId, storeObject);\n    });\n    store.retain(ref.__ref);\n    return ref;\n  };\n\n  StoreWriter.prototype.processSelectionSet = function (_a) {\n    var _this = this;\n\n    var dataId = _a.dataId,\n        result = _a.result,\n        selectionSet = _a.selectionSet,\n        context = _a.context,\n        mergeTree = _a.mergeTree;\n    var policies = this.cache.policies;\n    var incoming = Object.create(null);\n    var typename = dataId && policies.rootTypenamesById[dataId] || getTypenameFromResult(result, selectionSet, context.fragmentMap) || dataId && context.store.get(dataId, \"__typename\");\n\n    if (\"string\" === typeof typename) {\n      incoming.__typename = typename;\n    }\n\n    var readField = function () {\n      var options = normalizeReadFieldOptions(arguments, incoming, context.variables);\n\n      if (isReference(options.from)) {\n        var info = context.incomingById.get(options.from.__ref);\n\n        if (info) {\n          var result_1 = policies.readField(__assign(__assign({}, options), {\n            from: info.storeObject\n          }), context);\n\n          if (result_1 !== void 0) {\n            return result_1;\n          }\n        }\n      }\n\n      return policies.readField(options, context);\n    };\n\n    var fieldNodeSet = new Set();\n    this.flattenFields(selectionSet, result, context, typename).forEach(function (context, field) {\n      var _a;\n\n      var resultFieldKey = resultKeyNameFromField(field);\n      var value = result[resultFieldKey];\n      fieldNodeSet.add(field);\n\n      if (value !== void 0) {\n        var storeFieldName = policies.getStoreFieldName({\n          typename: typename,\n          fieldName: field.name.value,\n          field: field,\n          variables: context.variables\n        });\n        var childTree = getChildMergeTree(mergeTree, storeFieldName);\n\n        var incomingValue = _this.processFieldValue(value, field, field.selectionSet ? getContextFlavor(context, false, false) : context, childTree);\n\n        var childTypename = void 0;\n\n        if (field.selectionSet && (isReference(incomingValue) || storeValueIsStoreObject(incomingValue))) {\n          childTypename = readField(\"__typename\", incomingValue);\n        }\n\n        var merge = policies.getMergeFunction(typename, field.name.value, childTypename);\n\n        if (merge) {\n          childTree.info = {\n            field: field,\n            typename: typename,\n            merge: merge\n          };\n        } else {\n          maybeRecycleChildMergeTree(mergeTree, storeFieldName);\n        }\n\n        incoming = context.merge(incoming, (_a = {}, _a[storeFieldName] = incomingValue, _a));\n      } else if (__DEV__ && !context.clientOnly && !context.deferred && !addTypenameToDocument.added(field) && !policies.getReadFunction(typename, field.name.value)) {\n        __DEV__ && invariant.error(\"Missing field '\".concat(resultKeyNameFromField(field), \"' while writing result \").concat(JSON.stringify(result, null, 2)).substring(0, 1000));\n      }\n    });\n\n    try {\n      var _b = policies.identify(result, {\n        typename: typename,\n        selectionSet: selectionSet,\n        fragmentMap: context.fragmentMap,\n        storeObject: incoming,\n        readField: readField\n      }),\n          id = _b[0],\n          keyObject = _b[1];\n\n      dataId = dataId || id;\n\n      if (keyObject) {\n        incoming = context.merge(incoming, keyObject);\n      }\n    } catch (e) {\n      if (!dataId) throw e;\n    }\n\n    if (\"string\" === typeof dataId) {\n      var dataRef = makeReference(dataId);\n      var sets = context.written[dataId] || (context.written[dataId] = []);\n      if (sets.indexOf(selectionSet) >= 0) return dataRef;\n      sets.push(selectionSet);\n\n      if (this.reader && this.reader.isFresh(result, dataRef, selectionSet, context)) {\n        return dataRef;\n      }\n\n      var previous_1 = context.incomingById.get(dataId);\n\n      if (previous_1) {\n        previous_1.storeObject = context.merge(previous_1.storeObject, incoming);\n        previous_1.mergeTree = mergeMergeTrees(previous_1.mergeTree, mergeTree);\n        fieldNodeSet.forEach(function (field) {\n          return previous_1.fieldNodeSet.add(field);\n        });\n      } else {\n        context.incomingById.set(dataId, {\n          storeObject: incoming,\n          mergeTree: mergeTreeIsEmpty(mergeTree) ? void 0 : mergeTree,\n          fieldNodeSet: fieldNodeSet\n        });\n      }\n\n      return dataRef;\n    }\n\n    return incoming;\n  };\n\n  StoreWriter.prototype.processFieldValue = function (value, field, context, mergeTree) {\n    var _this = this;\n\n    if (!field.selectionSet || value === null) {\n      return __DEV__ ? cloneDeep(value) : value;\n    }\n\n    if (isArray(value)) {\n      return value.map(function (item, i) {\n        var value = _this.processFieldValue(item, field, context, getChildMergeTree(mergeTree, i));\n\n        maybeRecycleChildMergeTree(mergeTree, i);\n        return value;\n      });\n    }\n\n    return this.processSelectionSet({\n      result: value,\n      selectionSet: field.selectionSet,\n      context: context,\n      mergeTree: mergeTree\n    });\n  };\n\n  StoreWriter.prototype.flattenFields = function (selectionSet, result, context, typename) {\n    if (typename === void 0) {\n      typename = getTypenameFromResult(result, selectionSet, context.fragmentMap);\n    }\n\n    var fieldMap = new Map();\n    var policies = this.cache.policies;\n    var limitingTrie = new Trie(false);\n\n    (function flatten(selectionSet, inheritedContext) {\n      var visitedNode = limitingTrie.lookup(selectionSet, inheritedContext.clientOnly, inheritedContext.deferred);\n      if (visitedNode.visited) return;\n      visitedNode.visited = true;\n      selectionSet.selections.forEach(function (selection) {\n        if (!shouldInclude(selection, context.variables)) return;\n        var clientOnly = inheritedContext.clientOnly,\n            deferred = inheritedContext.deferred;\n\n        if (!(clientOnly && deferred) && isNonEmptyArray(selection.directives)) {\n          selection.directives.forEach(function (dir) {\n            var name = dir.name.value;\n            if (name === \"client\") clientOnly = true;\n\n            if (name === \"defer\") {\n              var args = argumentsObjectFromField(dir, context.variables);\n\n              if (!args || args.if !== false) {\n                deferred = true;\n              }\n            }\n          });\n        }\n\n        if (isField(selection)) {\n          var existing = fieldMap.get(selection);\n\n          if (existing) {\n            clientOnly = clientOnly && existing.clientOnly;\n            deferred = deferred && existing.deferred;\n          }\n\n          fieldMap.set(selection, getContextFlavor(context, clientOnly, deferred));\n        } else {\n          var fragment = getFragmentFromSelection(selection, context.fragmentMap);\n\n          if (fragment && policies.fragmentMatches(fragment, typename, result, context.variables)) {\n            flatten(fragment.selectionSet, getContextFlavor(context, clientOnly, deferred));\n          }\n        }\n      });\n    })(selectionSet, context);\n\n    return fieldMap;\n  };\n\n  StoreWriter.prototype.applyMerges = function (mergeTree, existing, incoming, context, getStorageArgs) {\n    var _a;\n\n    var _this = this;\n\n    if (mergeTree.map.size && !isReference(incoming)) {\n      var e_1 = !isArray(incoming) && (isReference(existing) || storeValueIsStoreObject(existing)) ? existing : void 0;\n      var i_1 = incoming;\n\n      if (e_1 && !getStorageArgs) {\n        getStorageArgs = [isReference(e_1) ? e_1.__ref : e_1];\n      }\n\n      var changedFields_1;\n\n      var getValue_1 = function (from, name) {\n        return isArray(from) ? typeof name === \"number\" ? from[name] : void 0 : context.store.getFieldValue(from, String(name));\n      };\n\n      mergeTree.map.forEach(function (childTree, storeFieldName) {\n        var eVal = getValue_1(e_1, storeFieldName);\n        var iVal = getValue_1(i_1, storeFieldName);\n        if (void 0 === iVal) return;\n\n        if (getStorageArgs) {\n          getStorageArgs.push(storeFieldName);\n        }\n\n        var aVal = _this.applyMerges(childTree, eVal, iVal, context, getStorageArgs);\n\n        if (aVal !== iVal) {\n          changedFields_1 = changedFields_1 || new Map();\n          changedFields_1.set(storeFieldName, aVal);\n        }\n\n        if (getStorageArgs) {\n          invariant(getStorageArgs.pop() === storeFieldName);\n        }\n      });\n\n      if (changedFields_1) {\n        incoming = isArray(i_1) ? i_1.slice(0) : __assign({}, i_1);\n        changedFields_1.forEach(function (value, name) {\n          incoming[name] = value;\n        });\n      }\n    }\n\n    if (mergeTree.info) {\n      return this.cache.policies.runMergeFunction(existing, incoming, mergeTree.info, context, getStorageArgs && (_a = context.store).getStorage.apply(_a, getStorageArgs));\n    }\n\n    return incoming;\n  };\n\n  return StoreWriter;\n}();\n\nexport { StoreWriter };\nvar emptyMergeTreePool = [];\n\nfunction getChildMergeTree(_a, name) {\n  var map = _a.map;\n\n  if (!map.has(name)) {\n    map.set(name, emptyMergeTreePool.pop() || {\n      map: new Map()\n    });\n  }\n\n  return map.get(name);\n}\n\nfunction mergeMergeTrees(left, right) {\n  if (left === right || !right || mergeTreeIsEmpty(right)) return left;\n  if (!left || mergeTreeIsEmpty(left)) return right;\n  var info = left.info && right.info ? __assign(__assign({}, left.info), right.info) : left.info || right.info;\n  var needToMergeMaps = left.map.size && right.map.size;\n  var map = needToMergeMaps ? new Map() : left.map.size ? left.map : right.map;\n  var merged = {\n    info: info,\n    map: map\n  };\n\n  if (needToMergeMaps) {\n    var remainingRightKeys_1 = new Set(right.map.keys());\n    left.map.forEach(function (leftTree, key) {\n      merged.map.set(key, mergeMergeTrees(leftTree, right.map.get(key)));\n      remainingRightKeys_1.delete(key);\n    });\n    remainingRightKeys_1.forEach(function (key) {\n      merged.map.set(key, mergeMergeTrees(right.map.get(key), left.map.get(key)));\n    });\n  }\n\n  return merged;\n}\n\nfunction mergeTreeIsEmpty(tree) {\n  return !tree || !(tree.info || tree.map.size);\n}\n\nfunction maybeRecycleChildMergeTree(_a, name) {\n  var map = _a.map;\n  var childTree = map.get(name);\n\n  if (childTree && mergeTreeIsEmpty(childTree)) {\n    emptyMergeTreePool.push(childTree);\n    map.delete(name);\n  }\n}\n\nvar warnings = new Set();\n\nfunction warnAboutDataLoss(existingRef, incomingObj, storeFieldName, store) {\n  var getChild = function (objOrRef) {\n    var child = store.getFieldValue(objOrRef, storeFieldName);\n    return typeof child === \"object\" && child;\n  };\n\n  var existing = getChild(existingRef);\n  if (!existing) return;\n  var incoming = getChild(incomingObj);\n  if (!incoming) return;\n  if (isReference(existing)) return;\n  if (equal(existing, incoming)) return;\n\n  if (Object.keys(existing).every(function (key) {\n    return store.getFieldValue(incoming, key) !== void 0;\n  })) {\n    return;\n  }\n\n  var parentType = store.getFieldValue(existingRef, \"__typename\") || store.getFieldValue(incomingObj, \"__typename\");\n  var fieldName = fieldNameFromStoreName(storeFieldName);\n  var typeDotName = \"\".concat(parentType, \".\").concat(fieldName);\n  if (warnings.has(typeDotName)) return;\n  warnings.add(typeDotName);\n  var childTypenames = [];\n\n  if (!isArray(existing) && !isArray(incoming)) {\n    [existing, incoming].forEach(function (child) {\n      var typename = store.getFieldValue(child, \"__typename\");\n\n      if (typeof typename === \"string\" && !childTypenames.includes(typename)) {\n        childTypenames.push(typename);\n      }\n    });\n  }\n\n  __DEV__ && invariant.warn(\"Cache data may be lost when replacing the \".concat(fieldName, \" field of a \").concat(parentType, \" object.\\n\\nTo address this problem (which is not a bug in Apollo Client), \").concat(childTypenames.length ? \"either ensure all objects of type \" + childTypenames.join(\" and \") + \" have an ID or a custom merge function, or \" : \"\", \"define a custom merge function for the \").concat(typeDotName, \" field, so InMemoryCache can safely merge these objects:\\n\\n  existing: \").concat(JSON.stringify(existing).slice(0, 1000), \"\\n  incoming: \").concat(JSON.stringify(incoming).slice(0, 1000), \"\\n\\nFor more information about these options, please refer to the documentation:\\n\\n  * Ensuring entity objects have IDs: https://go.apollo.dev/c/generating-unique-identifiers\\n  * Defining custom merge functions: https://go.apollo.dev/c/merging-non-normalized-objects\\n\"));\n}","map":{"version":3,"mappings":";AAAA,SAASA,SAAT,EAAoBC,cAApB,QAA0C,kCAA1C;AACA,SAASC,KAAT,QAAsB,eAAtB;AACA,SAASC,IAAT,QAAqB,WAArB;AAMA,SACEC,iBADF,EAGEC,wBAHF,EAIEC,gBAJF,EAKEC,sBALF,EAMEC,sBANF,EAOEC,qBAPF,EAQEC,aARF,EASEC,OATF,EAUEC,sBAVF,EAcEC,WAdF,EAeEC,aAfF,EAgBEC,SAhBF,EAiBEC,qBAjBF,EAkBEC,eAlBF,EAmBEC,wBAnBF,QAoBO,0BApBP;AAuBA,SAASC,yBAAT,EAAoCC,sBAApC,EAA4DC,uBAA5D,EAAqFC,OAArF,QAAoG,cAApG;AAKA,SAASC,kBAAT,QAAmC,mBAAnC;AACA,SAASC,yBAAT,QAA0C,eAA1C;AAuBC;;AAcD,SAASC,gBAAT,CACEC,OADF,EAEEC,UAFF,EAGEC,QAHF,EAGgC;AAE9B,MAAMC,GAAG,GAAG,UAAGF,UAAH,EAAaG,MAAb,CAAgBF,QAAhB,CAAZ;AACA,MAAIG,QAAQ,GAAGL,OAAO,CAACM,OAAR,CAAgBC,GAAhB,CAAoBJ,GAApB,CAAf;;AACA,MAAI,CAACE,QAAL,EAAe;AACbL,WAAO,CAACM,OAAR,CAAgBE,GAAhB,CAAoBL,GAApB,EAAyBE,QAAQ,GAC/BL,OAAO,CAACC,UAAR,KAAuBA,UAAvB,IACAD,OAAO,CAACE,QAAR,KAAqBA,QAFa,GAGhCF,OAHgC,GAGvBS,sBACRT,OADQ,GACD;AACVC,gBAAU,YADA;AAEVC,cAAQ;AAFE,KADC,CAHb;AAQD;;AACD,SAAOG,QAAP;AACD;;AAUD;AACE,uBACkBK,KADlB,EAEUC,MAFV,EAE8B;AADZ;AACR;AACN;;AAEGC,uCAAP,UAAoBC,KAApB,EAA4CC,EAA5C,EAMqB;AANrB;;QACEC,KAAK;QACLC,MAAM;QACNC,MAAM;QACNC,SAAS;QACTC,SAAS;AAET,QAAMC,mBAAmB,GAAGtC,sBAAsB,CAACiC,KAAD,CAAlD;AACA,QAAMM,MAAM,GAAG5B,yBAAyB,EAAxC;AAEAyB,aAAS,yBACJtC,gBAAgB,CAACwC,mBAAD,CADZ,GAEJF,SAFI,CAAT;AAKA,QAAMlB,OAAO,GAAiB;AAC5Ba,WAAK,OADuB;AAE5BS,aAAO,EAAEC,MAAM,CAACC,MAAP,CAAc,IAAd,CAFmB;AAG5BC,WAAK,EAAL,UAASC,QAAT,EAAsBC,QAAtB,EAAiC;AAC/B,eAAON,MAAM,CAACI,KAAP,CAAaC,QAAb,EAAuBC,QAAvB,CAAP;AACD,OAL2B;AAM5BT,eAAS,WANmB;AAO5BU,eAAS,EAAE/B,kBAAkB,CAACqB,SAAD,CAPD;AAQ5BW,iBAAW,EAAEnD,iBAAiB,CAACG,sBAAsB,CAACkC,KAAD,CAAvB,CARF;AAS5BI,eAAS,EAAE,CAAC,CAACA,SATe;AAU5BW,kBAAY,EAAE,IAAIC,GAAJ,EAVc;AAW5B9B,gBAAU,EAAE,KAXgB;AAY5BC,cAAQ,EAAE,KAZkB;AAa5BI,aAAO,EAAE,IAAIyB,GAAJ;AAbmB,KAA9B;AAgBA,QAAMC,GAAG,GAAG,KAAKC,mBAAL,CAAyB;AACnCjB,YAAM,EAAEA,MAAM,IAAIO,MAAM,CAACC,MAAP,CAAc,IAAd,CADiB;AAEnCP,YAAM,QAF6B;AAGnCiB,kBAAY,EAAEd,mBAAmB,CAACc,YAHC;AAInCC,eAAS,EAAE;AAAEC,WAAG,EAAE,IAAIL,GAAJ;AAAP,OAJwB;AAKnC/B,aAAO;AAL4B,KAAzB,CAAZ;;AAQA,QAAI,CAACb,WAAW,CAAC6C,GAAD,CAAhB,EAAuB;AACrB,YAAMK,OAAI,sBAAe,6BAA6BjC,MAA7B,CAAkCkC,IAAS,CAACC,SAAV,CAAqBvB,MAArB,CAAlC,CAAf,IAAsE,qBAAhF;AACD;;AAIDhB,WAAO,CAAC8B,YAAR,CAAqBU,OAArB,CAA6B,UAAC1B,EAAD,EAA2CG,MAA3C,EAAiD;UAA9CwB,WAAW;UAAEN,SAAS;UAAEO,YAAY;AAClE,UAAMC,SAAS,GAAG3D,aAAa,CAACiC,MAAD,CAA/B;;AAEA,UAAIkB,SAAS,IAAIA,SAAS,CAACC,GAAV,CAAcQ,IAA/B,EAAqC;AACnC,YAAMC,OAAO,GAAGC,KAAI,CAACC,WAAL,CAAiBZ,SAAjB,EAA4BQ,SAA5B,EAAuCF,WAAvC,EAAoDzC,OAApD,CAAhB;;AACA,YAAIb,WAAW,CAAC0D,OAAD,CAAf,EAA0B;AAIxB;AACD;;AAGDJ,mBAAW,GAAGI,OAAd;AACD;;AAED,UAAIR,OAAO,IAAI,CAACrC,OAAO,CAACmB,SAAxB,EAAmC;AACjC,YAAM6B,yBAAuB,GAAyBzB,MAAM,CAACC,MAAP,CAAc,IAAd,CAAtD;AACAkB,oBAAY,CAACF,OAAb,CAAqB,iBAAK;AACxB,cAAIS,KAAK,CAACf,YAAV,EAAwB;AACtBc,qCAAuB,CAACC,KAAK,CAACC,IAAN,CAAWC,KAAZ,CAAvB,GAA4C,IAA5C;AACD;AACF,SAJD;;AAMA,YAAMC,iBAAe,GAAG,UAACC,cAAD,EAAuB;AAC7C,0CAAuB,CACrB3D,sBAAsB,CAAC2D,cAAD,CADD,CAAvB,KAEM,IAFN;AAEU,SAHZ;;AAKA,YAAMC,kBAAgB,GAAG,UAACD,cAAD,EAAuB;AAC9C,cAAME,SAAS,GAAGpB,SAAS,IAAIA,SAAS,CAACC,GAAV,CAAc7B,GAAd,CAAkB8C,cAAlB,CAA/B;AACA,iBAAOG,OAAO,CAACD,SAAS,IAAIA,SAAS,CAACE,IAAvB,IAA+BF,SAAS,CAACE,IAAV,CAAehC,KAA/C,CAAd;AACD,SAHD;;AAKAF,cAAM,CAACmC,IAAP,CAAYjB,WAAZ,EAAyBD,OAAzB,CAAiC,0BAAc;AAK7C,cAAIY,iBAAe,CAACC,cAAD,CAAf,IACA,CAACC,kBAAgB,CAACD,cAAD,CADrB,EACuC;AACrCM,6BAAiB,CACfhB,SADe,EAEfF,WAFe,EAGfY,cAHe,EAIfrD,OAAO,CAACa,KAJO,CAAjB;AAMD;AACF,SAdD;AAeD;;AAEDA,WAAK,CAACY,KAAN,CAAYR,MAAZ,EAAoBwB,WAApB;AACD,KApDD;AA2DA5B,SAAK,CAAC+C,MAAN,CAAa5B,GAAG,CAAC6B,KAAjB;AAEA,WAAO7B,GAAP;AACD,GA3GM;;AA6GCpB,8CAAR,UAA4BE,EAA5B,EAQ6B;AAR7B;;QACEG,MAAM;QACND,MAAM;QACNkB,YAAY;QACZlC,OAAO;QAGPmC,SAAS;AAED,gBAAQ,GAAK,KAAKzB,KAAL,CAAUoD,QAAvB;AAIR,QAAInC,QAAQ,GAAgBJ,MAAM,CAACC,MAAP,CAAc,IAAd,CAA5B;AAKA,QAAMuC,QAAQ,GACX9C,MAAM,IAAI6C,QAAQ,CAACE,iBAAT,CAA2B/C,MAA3B,CAAX,IACAlC,qBAAqB,CAACiC,MAAD,EAASkB,YAAT,EAAuBlC,OAAO,CAAC6B,WAA/B,CADrB,IAECZ,MAAM,IAAIjB,OAAO,CAACa,KAAR,CAAcN,GAAd,CAAkBU,MAAlB,EAA0B,YAA1B,CAHb;;AAKA,QAAI,aAAa,OAAO8C,QAAxB,EAAkC;AAChCpC,cAAQ,CAACsC,UAAT,GAAsBF,QAAtB;AACD;;AAUD,QAAMG,SAAS,GAAsB;AACnC,UAAMC,OAAO,GAAGrE,yBAAyB,CACvCsE,SADuC,EAEvCzC,QAFuC,EAGvC3B,OAAO,CAACkB,SAH+B,CAAzC;;AAMA,UAAI/B,WAAW,CAACgF,OAAO,CAACE,IAAT,CAAf,EAA+B;AAC7B,YAAMZ,IAAI,GAAGzD,OAAO,CAAC8B,YAAR,CAAqBvB,GAArB,CAAyB4D,OAAO,CAACE,IAAR,CAAaR,KAAtC,CAAb;;AACA,YAAIJ,IAAJ,EAAU;AACR,cAAMa,QAAM,GAAGR,QAAQ,CAACI,SAAT,CAAkBzD,sBAC5B0D,OAD4B,GACrB;AACVE,gBAAI,EAAEZ,IAAI,CAAChB;AADD,WADqB,CAAlB,EAGZzC,OAHY,CAAf;;AAKA,cAAIsE,QAAM,KAAK,KAAK,CAApB,EAAuB;AACrB,mBAAOA,QAAP;AACD;AACF;AACF;;AAED,aAAOR,QAAQ,CAACI,SAAT,CAAmBC,OAAnB,EAA4BnE,OAA5B,CAAP;AACD,KAtBD;;AAwBA,QAAM0C,YAAY,GAAG,IAAI6B,GAAJ,EAArB;AAEA,SAAKC,aAAL,CACEtC,YADF,EAEElB,MAFF,EAMEhB,OANF,EAOE+D,QAPF,EAQEvB,OARF,CAQU,UAACxC,OAAD,EAAUiD,KAAV,EAAe;;;AACvB,UAAMwB,cAAc,GAAGvF,sBAAsB,CAAC+D,KAAD,CAA7C;AACA,UAAME,KAAK,GAAGnC,MAAM,CAACyD,cAAD,CAApB;AAEA/B,kBAAY,CAACgC,GAAb,CAAiBzB,KAAjB;;AAEA,UAAIE,KAAK,KAAK,KAAK,CAAnB,EAAsB;AACpB,YAAME,cAAc,GAAGS,QAAQ,CAACa,iBAAT,CAA2B;AAChDZ,kBAAQ,UADwC;AAEhDa,mBAAS,EAAE3B,KAAK,CAACC,IAAN,CAAWC,KAF0B;AAGhDF,eAAK,OAH2C;AAIhD/B,mBAAS,EAAElB,OAAO,CAACkB;AAJ6B,SAA3B,CAAvB;AAOA,YAAMqC,SAAS,GAAGsB,iBAAiB,CAAC1C,SAAD,EAAYkB,cAAZ,CAAnC;;AAEA,YAAIyB,aAAa,GAAGhC,KAAI,CAACiC,iBAAL,CAClB5B,KADkB,EAElBF,KAFkB,EAKlBA,KAAK,CAACf,YAAN,GACInC,gBAAgB,CAACC,OAAD,EAAU,KAAV,EAAiB,KAAjB,CADpB,GAEIA,OAPc,EAQlBuD,SARkB,CAApB;;AAcA,YAAIyB,aAAa,SAAjB;;AAIA,YAAI/B,KAAK,CAACf,YAAN,KACC/C,WAAW,CAAC2F,aAAD,CAAX,IACAnF,uBAAuB,CAACmF,aAAD,CAFxB,CAAJ,EAE8C;AAC5CE,uBAAa,GAAGd,SAAS,CAAS,YAAT,EAAuBY,aAAvB,CAAzB;AACD;;AAED,YAAMrD,KAAK,GAAGqC,QAAQ,CAACmB,gBAAT,CACZlB,QADY,EAEZd,KAAK,CAACC,IAAN,CAAWC,KAFC,EAGZ6B,aAHY,CAAd;;AAMA,YAAIvD,KAAJ,EAAW;AACT8B,mBAAS,CAACE,IAAV,GAAiB;AAEfR,iBAAK,OAFU;AAGfc,oBAAQ,UAHO;AAIftC,iBAAK;AAJU,WAAjB;AAMD,SAPD,MAOO;AACLyD,oCAA0B,CAAC/C,SAAD,EAAYkB,cAAZ,CAA1B;AACD;;AAED1B,gBAAQ,GAAG3B,OAAO,CAACyB,KAAR,CAAcE,QAAd,GAAsBb,SAC/BA,GAACuC,cAAD,IAAkByB,aADa,IAAtB,EAAX;AAID,OAvDD,MAuDO,IACLzC,OAAO,IACP,CAACrC,OAAO,CAACC,UADT,IAEA,CAACD,OAAO,CAACE,QAFT,IAGA,CAACZ,qBAAqB,CAAC6F,KAAtB,CAA4BlC,KAA5B,CAHD,IAOA,CAACa,QAAQ,CAACsB,eAAT,CAAyBrB,QAAzB,EAAmCd,KAAK,CAACC,IAAN,CAAWC,KAA9C,CARI,EASL;AACAd,mBAAU/D,SAAM,MAAN,CAAM,kBACd8B,MADc,CACdlB,sBAA6B,OADf,EACe,yBADf,EAGVkB,MAHU,CAGTkC,IAAU,UAAV,CAAkBtB,MAAlB,EACJ,IADI,EACJ,CADI,CAHS,EAIFqE,SAJE,CAIO,CAJP,EAIO,IAJP,CAAN,CAAV;AAKD;AACF,KArFD;;AAyFA,QAAI;AACI,eAAkBvB,QAAQ,CAACwB,QAAT,CAAkBtE,MAAlB,EAA0B;AAChD+C,gBAAQ,UADwC;AAEhD7B,oBAAY,cAFoC;AAGhDL,mBAAW,EAAE7B,OAAO,CAAC6B,WAH2B;AAIhDY,mBAAW,EAAEd,QAJmC;AAKhDuC,iBAAS;AALuC,OAA1B,CAAlB;AAAA,UAACqB,EAAE,QAAH;AAAA,UAAKC,SAAS,QAAd;;AAUNvE,YAAM,GAAGA,MAAM,IAAIsE,EAAnB;;AAIA,UAAIC,SAAJ,EAAe;AAEb7D,gBAAQ,GAAG3B,OAAO,CAACyB,KAAR,CAAcE,QAAd,EAAwB6D,SAAxB,CAAX;AACD;AACF,KAnBD,CAmBE,OAAOC,CAAP,EAAU;AAEV,UAAI,CAACxE,MAAL,EAAa,MAAMwE,CAAN;AACd;;AAED,QAAI,aAAa,OAAOxE,MAAxB,EAAgC;AAC9B,UAAMyE,OAAO,GAAG1G,aAAa,CAACiC,MAAD,CAA7B;AAOA,UAAM0E,IAAI,GAAG3F,OAAO,CAACsB,OAAR,CAAgBL,MAAhB,MAA4BjB,OAAO,CAACsB,OAAR,CAAgBL,MAAhB,IAA0B,EAAtD,CAAb;AACA,UAAI0E,IAAI,CAACC,OAAL,CAAa1D,YAAb,KAA8B,CAAlC,EAAqC,OAAOwD,OAAP;AACrCC,UAAI,CAACE,IAAL,CAAU3D,YAAV;;AAOA,UAAI,KAAKvB,MAAL,IAAe,KAAKA,MAAL,CAAYmF,OAAZ,CACjB9E,MADiB,EAEjB0E,OAFiB,EAGjBxD,YAHiB,EAIjBlC,OAJiB,CAAnB,EAKG;AACD,eAAO0F,OAAP;AACD;;AAED,UAAMK,UAAQ,GAAG/F,OAAO,CAAC8B,YAAR,CAAqBvB,GAArB,CAAyBU,MAAzB,CAAjB;;AACA,UAAI8E,UAAJ,EAAc;AACZA,kBAAQ,CAACtD,WAAT,GAAuBzC,OAAO,CAACyB,KAAR,CAAcsE,UAAQ,CAACtD,WAAvB,EAAoCd,QAApC,CAAvB;AACAoE,kBAAQ,CAAC5D,SAAT,GAAqB6D,eAAe,CAACD,UAAQ,CAAC5D,SAAV,EAAqBA,SAArB,CAApC;AACAO,oBAAY,CAACF,OAAb,CAAqB,iBAAK;AAAI,2BAAQ,CAACE,YAAT,CAAsBgC,GAAtB,CAA0BzB,KAA1B;AAAgC,SAA9D;AACD,OAJD,MAIO;AACLjD,eAAO,CAAC8B,YAAR,CAAqBtB,GAArB,CAAyBS,MAAzB,EAAiC;AAC/BwB,qBAAW,EAAEd,QADkB;AAK/BQ,mBAAS,EAAE8D,gBAAgB,CAAC9D,SAAD,CAAhB,GAA8B,KAAK,CAAnC,GAAuCA,SALnB;AAM/BO,sBAAY;AANmB,SAAjC;AAQD;;AAED,aAAOgD,OAAP;AACD;;AAED,WAAO/D,QAAP;AACD,GA5NO;;AA8NAf,4CAAR,UACEuC,KADF,EAEEF,KAFF,EAGEjD,OAHF,EAIEmC,SAJF,EAIsB;AAJtB;;AAME,QAAI,CAACc,KAAK,CAACf,YAAP,IAAuBiB,KAAK,KAAK,IAArC,EAA2C;AAIzC,aAAOd,OAAO,GAAGhD,SAAS,CAAC8D,KAAD,CAAZ,GAAsBA,KAApC;AACD;;AAED,QAAIvD,OAAO,CAACuD,KAAD,CAAX,EAAoB;AAClB,aAAOA,KAAK,CAACf,GAAN,CAAU,UAAC8D,IAAD,EAAOC,CAAP,EAAQ;AACvB,YAAMhD,KAAK,GAAGL,KAAI,CAACiC,iBAAL,CACZmB,IADY,EACNjD,KADM,EACCjD,OADD,EACU6E,iBAAiB,CAAC1C,SAAD,EAAYgE,CAAZ,CAD3B,CAAd;;AAEAjB,kCAA0B,CAAC/C,SAAD,EAAYgE,CAAZ,CAA1B;AACA,eAAOhD,KAAP;AACD,OALM,CAAP;AAMD;;AAED,WAAO,KAAKlB,mBAAL,CAAyB;AAC9BjB,YAAM,EAAEmC,KADsB;AAE9BjB,kBAAY,EAAEe,KAAK,CAACf,YAFU;AAG9BlC,aAAO,SAHuB;AAI9BmC,eAAS;AAJqB,KAAzB,CAAP;AAMD,GA5BO;;AAgCAvB,wCAAR,UAQEsB,YARF,EASElB,MATF,EAUEhB,OAVF,EAWE+D,QAXF,EAW6E;AAA3E;AAAAA,iBAAWhF,qBAAqB,CAACiC,MAAD,EAASkB,YAAT,EAAuBlC,OAAO,CAAC6B,WAA/B,CAAhC;AAA2E;;AAE3E,QAAMuE,QAAQ,GAAG,IAAIrE,GAAJ,EAAjB;AACQ,gBAAQ,GAAK,KAAKrB,KAAL,CAAUoD,QAAvB;AAER,QAAMuC,YAAY,GAAG,IAAI5H,IAAJ,CAUlB,KAVkB,CAArB;;AAYA,KAAC,SAAS6H,OAAT,CAECpE,YAFD,EAGCqE,gBAHD,EAG2B;AAE1B,UAAMC,WAAW,GAAGH,YAAY,CAACI,MAAb,CAClBvE,YADkB,EAMlBqE,gBAAgB,CAACtG,UANC,EAOlBsG,gBAAgB,CAACrG,QAPC,CAApB;AASA,UAAIsG,WAAW,CAACE,OAAhB,EAAyB;AACzBF,iBAAW,CAACE,OAAZ,GAAsB,IAAtB;AAEAxE,kBAAY,CAACyE,UAAb,CAAwBnE,OAAxB,CAAgC,qBAAS;AACvC,YAAI,CAACpD,aAAa,CAACwH,SAAD,EAAY5G,OAAO,CAACkB,SAApB,CAAlB,EAAkD;AAE5C,sBAAU,GAAeqF,gBAAgB,WAAzC;AAAA,YAAYrG,QAAQ,GAAKqG,gBAAgB,SAAzC;;AACN,YAIE,EAAEtG,UAAU,IAAIC,QAAhB,KACAX,eAAe,CAACqH,SAAS,CAACC,UAAX,CALjB,EAME;AACAD,mBAAS,CAACC,UAAV,CAAqBrE,OAArB,CAA6B,eAAG;AAC9B,gBAAMU,IAAI,GAAG4D,GAAG,CAAC5D,IAAJ,CAASC,KAAtB;AACA,gBAAID,IAAI,KAAK,QAAb,EAAuBjD,UAAU,GAAG,IAAb;;AACvB,gBAAIiD,IAAI,KAAK,OAAb,EAAsB;AACpB,kBAAM6D,IAAI,GAAGvH,wBAAwB,CAACsH,GAAD,EAAM9G,OAAO,CAACkB,SAAd,CAArC;;AAKA,kBAAI,CAAC6F,IAAD,IAAUA,IAAyB,CAACC,EAA1B,KAAiC,KAA/C,EAAsD;AACpD9G,wBAAQ,GAAG,IAAX;AACD;AAGF;AACF,WAfD;AAgBD;;AAED,YAAIjB,OAAO,CAAC2H,SAAD,CAAX,EAAwB;AACtB,cAAMlF,QAAQ,GAAG0E,QAAQ,CAAC7F,GAAT,CAAaqG,SAAb,CAAjB;;AACA,cAAIlF,QAAJ,EAAc;AAIZzB,sBAAU,GAAGA,UAAU,IAAIyB,QAAQ,CAACzB,UAApC;AACAC,oBAAQ,GAAGA,QAAQ,IAAIwB,QAAQ,CAACxB,QAAhC;AACD;;AAEDkG,kBAAQ,CAAC5F,GAAT,CACEoG,SADF,EAEE7G,gBAAgB,CAACC,OAAD,EAAUC,UAAV,EAAsBC,QAAtB,CAFlB;AAKD,SAfD,MAeO;AACL,cAAM+G,QAAQ,GACZtI,wBAAwB,CAACiI,SAAD,EAAY5G,OAAO,CAAC6B,WAApB,CAD1B;;AAGA,cAAIoF,QAAQ,IACRnD,QAAQ,CAACoD,eAAT,CACED,QADF,EACYlD,QADZ,EACsB/C,MADtB,EAC8BhB,OAAO,CAACkB,SADtC,CADJ,EAEsD;AAEpDoF,mBAAO,CACLW,QAAQ,CAAC/E,YADJ,EAELnC,gBAAgB,CAACC,OAAD,EAAUC,UAAV,EAAsBC,QAAtB,CAFX,CAAP;AAID;AACF;AACF,OA1DD;AA2DD,KA5ED,EA4EGgC,YA5EH,EA4EiBlC,OA5EjB;;AA8EA,WAAOoG,QAAP;AACD,GA3GO;;AA6GAxF,sCAAR,UACEuB,SADF,EAEET,QAFF,EAGEC,QAHF,EAIE3B,OAJF,EAKEmH,cALF,EAKwD;;;AALxD;;AAOE,QAAIhF,SAAS,CAACC,GAAV,CAAcQ,IAAd,IAAsB,CAACzD,WAAW,CAACwC,QAAD,CAAtC,EAAkD;AAChD,UAAMyF,GAAC,GAIL,CAACxH,OAAO,CAAC+B,QAAD,CAAR,KAICxC,WAAW,CAACuC,QAAD,CAAX,IAAyB/B,uBAAuB,CAAC+B,QAAD,CAJjD,CAJ6C,GAS3CA,QAT2C,GAShC,KAAK,CATpB;AAcA,UAAM2F,GAAC,GAAG1F,QAAV;;AAMA,UAAIyF,GAAC,IAAI,CAACD,cAAV,EAA0B;AACxBA,sBAAc,GAAG,CAAChI,WAAW,CAACiI,GAAD,CAAX,GAAiBA,GAAC,CAACvD,KAAnB,GAA2BuD,GAA5B,CAAjB;AACD;;AAOD,UAAIE,eAAJ;;AAEA,UAAMC,UAAQ,GAAG,UACflD,IADe,EAEfnB,IAFe,EAEM;AAErB,eAAOtD,OAAO,CAACyE,IAAD,CAAP,GACF,OAAOnB,IAAP,KAAgB,QAAhB,GAA2BmB,IAAI,CAACnB,IAAD,CAA/B,GAAwC,KAAK,CAD3C,GAEHlD,OAAO,CAACa,KAAR,CAAc2G,aAAd,CAA4BnD,IAA5B,EAAkCoD,MAAM,CAACvE,IAAD,CAAxC,CAFJ;AAGD,OAPD;;AASAf,eAAS,CAACC,GAAV,CAAcI,OAAd,CAAsB,UAACe,SAAD,EAAYF,cAAZ,EAA0B;AAC9C,YAAMqE,IAAI,GAAGH,UAAQ,CAACH,GAAD,EAAI/D,cAAJ,CAArB;AACA,YAAMsE,IAAI,GAAGJ,UAAQ,CAACF,GAAD,EAAIhE,cAAJ,CAArB;AAEA,YAAI,KAAK,CAAL,KAAWsE,IAAf,EAAqB;;AACrB,YAAIR,cAAJ,EAAoB;AAClBA,wBAAc,CAACtB,IAAf,CAAoBxC,cAApB;AACD;;AACD,YAAMuE,IAAI,GAAG9E,KAAI,CAACC,WAAL,CACXQ,SADW,EAEXmE,IAFW,EAGXC,IAHW,EAIX3H,OAJW,EAKXmH,cALW,CAAb;;AAOA,YAAIS,IAAI,KAAKD,IAAb,EAAmB;AACjBL,yBAAa,GAAGA,eAAa,IAAI,IAAIvF,GAAJ,EAAjC;AACAuF,yBAAa,CAAC9G,GAAd,CAAkB6C,cAAlB,EAAkCuE,IAAlC;AACD;;AACD,YAAIT,cAAJ,EAAoB;AAClB7I,mBAAS,CAAC6I,cAAc,CAACU,GAAf,OAAyBxE,cAA1B,CAAT;AACD;AACF,OAtBD;;AAwBA,UAAIiE,eAAJ,EAAmB;AAEjB3F,gBAAQ,GAAI/B,OAAO,CAACyH,GAAD,CAAP,GAAaA,GAAC,CAACS,KAAF,CAAQ,CAAR,CAAb,GAAyBrH,aAAM4G,GAAN,CAArC;AACAC,uBAAa,CAAC9E,OAAd,CAAsB,UAACW,KAAD,EAAQD,IAAR,EAAY;AAC/BvB,kBAAgB,CAACuB,IAAD,CAAhB,GAAyBC,KAAzB;AACF,SAFD;AAGD;AACF;;AAED,QAAIhB,SAAS,CAACsB,IAAd,EAAoB;AAClB,aAAO,KAAK/C,KAAL,CAAWoD,QAAX,CAAoBiE,gBAApB,CACLrG,QADK,EAELC,QAFK,EAGLQ,SAAS,CAACsB,IAHL,EAILzD,OAJK,EAKLmH,cAAc,IAAI,aAAO,CAACtG,KAAR,EAAcmH,UAAd,CAAwBC,KAAxB,CAAwBnH,EAAxB,EAA4BqG,cAA5B,CALb,CAAP;AAOD;;AAED,WAAOxF,QAAP;AACD,GA5FO;;AA6FV;AAAC,CA3jBD;;;AA6jBA,IAAMuG,kBAAkB,GAAgB,EAAxC;;AAEA,SAASrD,iBAAT,CACE/D,EADF,EAEEoC,IAFF,EAEuB;MADnBd,GAAG;;AAGL,MAAI,CAACA,GAAG,CAAC+F,GAAJ,CAAQjF,IAAR,CAAL,EAAoB;AAClBd,OAAG,CAAC5B,GAAJ,CAAQ0C,IAAR,EAAcgF,kBAAkB,CAACL,GAAnB,MAA4B;AAAEzF,SAAG,EAAE,IAAIL,GAAJ;AAAP,KAA1C;AACD;;AACD,SAAOK,GAAG,CAAC7B,GAAJ,CAAQ2C,IAAR,CAAP;AACD;;AAED,SAAS8C,eAAT,CACEoC,IADF,EAEEC,KAFF,EAE8B;AAE5B,MAAID,IAAI,KAAKC,KAAT,IAAkB,CAACA,KAAnB,IAA4BpC,gBAAgB,CAACoC,KAAD,CAAhD,EAAyD,OAAOD,IAAP;AACzD,MAAI,CAACA,IAAD,IAASnC,gBAAgB,CAACmC,IAAD,CAA7B,EAAqC,OAAOC,KAAP;AAErC,MAAM5E,IAAI,GAAG2E,IAAI,CAAC3E,IAAL,IAAa4E,KAAK,CAAC5E,IAAnB,GAAyBhD,sBACjC2H,IAAI,CAAC3E,IAD4B,GAEjC4E,KAAK,CAAC5E,IAF2B,CAAzB,GAGT2E,IAAI,CAAC3E,IAAL,IAAa4E,KAAK,CAAC5E,IAHvB;AAKA,MAAM6E,eAAe,GAAGF,IAAI,CAAChG,GAAL,CAASQ,IAAT,IAAiByF,KAAK,CAACjG,GAAN,CAAUQ,IAAnD;AACA,MAAMR,GAAG,GAAGkG,eAAe,GAAG,IAAIvG,GAAJ,EAAH,GACzBqG,IAAI,CAAChG,GAAL,CAASQ,IAAT,GAAgBwF,IAAI,CAAChG,GAArB,GAA2BiG,KAAK,CAACjG,GADnC;AAGA,MAAMmG,MAAM,GAAG;AAAE9E,QAAI,MAAN;AAAQrB,OAAG;AAAX,GAAf;;AAEA,MAAIkG,eAAJ,EAAqB;AACnB,QAAME,oBAAkB,GAAG,IAAIjE,GAAJ,CAAQ8D,KAAK,CAACjG,GAAN,CAAUsB,IAAV,EAAR,CAA3B;AAEA0E,QAAI,CAAChG,GAAL,CAASI,OAAT,CAAiB,UAACiG,QAAD,EAAWtI,GAAX,EAAc;AAC7BoI,YAAM,CAACnG,GAAP,CAAW5B,GAAX,CACEL,GADF,EAEE6F,eAAe,CAACyC,QAAD,EAAWJ,KAAK,CAACjG,GAAN,CAAU7B,GAAV,CAAcJ,GAAd,CAAX,CAFjB;AAIAqI,0BAAkB,CAACE,MAAnB,CAA0BvI,GAA1B;AACD,KAND;AAQAqI,wBAAkB,CAAChG,OAAnB,CAA2B,eAAG;AAC5B+F,YAAM,CAACnG,GAAP,CAAW5B,GAAX,CACEL,GADF,EAEE6F,eAAe,CACbqC,KAAK,CAACjG,GAAN,CAAU7B,GAAV,CAAcJ,GAAd,CADa,EAEbiI,IAAI,CAAChG,GAAL,CAAS7B,GAAT,CAAaJ,GAAb,CAFa,CAFjB;AAOD,KARD;AASD;;AAED,SAAOoI,MAAP;AACD;;AAED,SAAStC,gBAAT,CAA0B0C,IAA1B,EAAqD;AACnD,SAAO,CAACA,IAAD,IAAS,EAAEA,IAAI,CAAClF,IAAL,IAAakF,IAAI,CAACvG,GAAL,CAASQ,IAAxB,CAAhB;AACD;;AAED,SAASsC,0BAAT,CACEpE,EADF,EAEEoC,IAFF,EAEuB;MADnBd,GAAG;AAGL,MAAMmB,SAAS,GAAGnB,GAAG,CAAC7B,GAAJ,CAAQ2C,IAAR,CAAlB;;AACA,MAAIK,SAAS,IAAI0C,gBAAgB,CAAC1C,SAAD,CAAjC,EAA8C;AAC5C2E,sBAAkB,CAACrC,IAAnB,CAAwBtC,SAAxB;AACAnB,OAAG,CAACsG,MAAJ,CAAWxF,IAAX;AACD;AACF;;AAED,IAAM0F,QAAQ,GAAG,IAAIrE,GAAJ,EAAjB;;AAIA,SAASZ,iBAAT,CACEkF,WADF,EAEEC,WAFF,EAGEzF,cAHF,EAIExC,KAJF,EAIwB;AAEtB,MAAMkI,QAAQ,GAAG,UAACC,QAAD,EAAkC;AACjD,QAAMC,KAAK,GAAGpI,KAAK,CAAC2G,aAAN,CAAiCwB,QAAjC,EAA2C3F,cAA3C,CAAd;AACA,WAAO,OAAO4F,KAAP,KAAiB,QAAjB,IAA6BA,KAApC;AACD,GAHD;;AAKA,MAAMvH,QAAQ,GAAGqH,QAAQ,CAACF,WAAD,CAAzB;AACA,MAAI,CAACnH,QAAL,EAAe;AAEf,MAAMC,QAAQ,GAAGoH,QAAQ,CAACD,WAAD,CAAzB;AACA,MAAI,CAACnH,QAAL,EAAe;AAIf,MAAIxC,WAAW,CAACuC,QAAD,CAAf,EAA2B;AAI3B,MAAIlD,KAAK,CAACkD,QAAD,EAAWC,QAAX,CAAT,EAA+B;;AAK/B,MAAIJ,MAAM,CAACmC,IAAP,CAAYhC,QAAZ,EAAsBwH,KAAtB,CACF,eAAG;AAAI,gBAAK,CAAC1B,aAAN,CAAoB7F,QAApB,EAA8BxB,GAA9B,MAAuC,KAAK,CAA5C;AAA6C,GADlD,CAAJ,EACyD;AACvD;AACD;;AAED,MAAMgJ,UAAU,GACdtI,KAAK,CAAC2G,aAAN,CAA4BqB,WAA5B,EAAyC,YAAzC,KACAhI,KAAK,CAAC2G,aAAN,CAA4BsB,WAA5B,EAAyC,YAAzC,CAFF;AAGA,MAAMlE,SAAS,GAAGlF,sBAAsB,CAAC2D,cAAD,CAAxC;AACA,MAAM+F,WAAW,GAAG,UAAGD,UAAH,EAAa,GAAb,EAAa/I,MAAb,CAAiBwE,SAAjB,CAApB;AAEA,MAAIgE,QAAQ,CAACT,GAAT,CAAaiB,WAAb,CAAJ,EAA+B;AAC/BR,UAAQ,CAAClE,GAAT,CAAa0E,WAAb;AAEA,MAAMC,cAAc,GAAa,EAAjC;;AAGA,MAAI,CAACzJ,OAAO,CAAC8B,QAAD,CAAR,IACA,CAAC9B,OAAO,CAAC+B,QAAD,CADZ,EACwB;AACtB,KAACD,QAAD,EAAWC,QAAX,EAAqBa,OAArB,CAA6B,iBAAK;AAChC,UAAMuB,QAAQ,GAAGlD,KAAK,CAAC2G,aAAN,CAAoByB,KAApB,EAA2B,YAA3B,CAAjB;;AACA,UAAI,OAAOlF,QAAP,KAAoB,QAApB,IACA,CAACsF,cAAc,CAACC,QAAf,CAAwBvF,QAAxB,CADL,EACwC;AACtCsF,sBAAc,CAACxD,IAAf,CAAoB9B,QAApB;AACD;AACF,KAND;AAOD;;AAED1B,aAAU/D,SACZ,KADY,CACZ,6CAA6C8B,MAA7C,CAAsDwE,SAAtD,EAAsD,cAAtD,EAAqExE,MAArE,CAA+E+I,UAA/E,EAA+E,6EAA/E,EAGE/I,MAHF,CAGEiJ,cAAqB,OAArB,GACI,uCACEA,cAAc,CAACE,IAAf,CAAoB,OAApB,CADF,GACiC,6CAFrC,GAGI,EANN,EAMQ,yCANR,EAMQnJ,MANR,CAQEgJ,WARF,EAQa,0EARb,EAQahJ,MARb,CAWckC,IAAI,CAACC,SAAL,CAAeb,QAAf,EAAyBoG,KAAzB,CAA+B,CAA/B,EAAkC,IAAlC,CAXd,EAWqD,gBAXrD,EAWqD1H,MAXrD,CAYckC,IAAI,CAACC,SAAL,CAAeZ,QAAf,EAAyBmG,KAAzB,CAA+B,CAA/B,EAAkC,IAAlC,CAZd,EAYqD,gRAZrD,CADY,CAAV;AAoBD","names":["invariant","InvariantError","equal","Trie","createFragmentMap","getFragmentFromSelection","getDefaultValues","getFragmentDefinitions","getOperationDefinition","getTypenameFromResult","makeReference","isField","resultKeyNameFromField","isReference","shouldInclude","cloneDeep","addTypenameToDocument","isNonEmptyArray","argumentsObjectFromField","makeProcessedFieldsMerger","fieldNameFromStoreName","storeValueIsStoreObject","isArray","canonicalStringify","normalizeReadFieldOptions","getContextFlavor","context","clientOnly","deferred","key","concat","flavored","flavors","get","set","__assign","cache","reader","StoreWriter","store","_a","query","result","dataId","variables","overwrite","operationDefinition","merger","written","Object","create","merge","existing","incoming","varString","fragmentMap","incomingById","Map","ref","processSelectionSet","selectionSet","mergeTree","map","__DEV__","JSON","stringify","forEach","storeObject","fieldNodeSet","entityRef","size","applied","_this","applyMerges","fieldsWithSelectionSets_1","field","name","value","hasSelectionSet_1","storeFieldName","hasMergeFunction_1","childTree","Boolean","info","keys","warnAboutDataLoss","retain","__ref","policies","typename","rootTypenamesById","__typename","readField","options","arguments","from","result_1","Set","flattenFields","resultFieldKey","add","getStoreFieldName","fieldName","getChildMergeTree","incomingValue","processFieldValue","childTypename","getMergeFunction","maybeRecycleChildMergeTree","added","getReadFunction","substring","identify","id","keyObject","e","dataRef","sets","indexOf","push","isFresh","previous_1","mergeMergeTrees","mergeTreeIsEmpty","item","i","fieldMap","limitingTrie","flatten","inheritedContext","visitedNode","lookup","visited","selections","selection","directives","dir","args","if","fragment","fragmentMatches","getStorageArgs","e_1","i_1","changedFields_1","getValue_1","getFieldValue","String","eVal","iVal","aVal","pop","slice","runMergeFunction","getStorage","apply","emptyMergeTreePool","has","left","right","needToMergeMaps","merged","remainingRightKeys_1","leftTree","delete","tree","warnings","existingRef","incomingObj","getChild","objOrRef","child","every","parentType","typeDotName","childTypenames","includes","join"],"sources":["C:\\Users\\poohb\\Desktop\\group-project-3\\client\\node_modules\\@apollo\\src\\cache\\inmemory\\writeToStore.ts"],"sourcesContent":["import { invariant, InvariantError } from '../../utilities/globals';\nimport { equal } from '@wry/equality';\nimport { Trie } from '@wry/trie';\nimport {\n  SelectionSetNode,\n  FieldNode,\n} from 'graphql';\n\nimport {\n  createFragmentMap,\n  FragmentMap,\n  getFragmentFromSelection,\n  getDefaultValues,\n  getFragmentDefinitions,\n  getOperationDefinition,\n  getTypenameFromResult,\n  makeReference,\n  isField,\n  resultKeyNameFromField,\n  StoreValue,\n  StoreObject,\n  Reference,\n  isReference,\n  shouldInclude,\n  cloneDeep,\n  addTypenameToDocument,\n  isNonEmptyArray,\n  argumentsObjectFromField,\n} from '../../utilities';\n\nimport { NormalizedCache, ReadMergeModifyContext, MergeTree } from './types';\nimport { makeProcessedFieldsMerger, fieldNameFromStoreName, storeValueIsStoreObject, isArray } from './helpers';\nimport { StoreReader } from './readFromStore';\nimport { InMemoryCache } from './inMemoryCache';\nimport { EntityStore } from './entityStore';\nimport { Cache } from '../../core';\nimport { canonicalStringify } from './object-canon';\nimport { normalizeReadFieldOptions } from './policies';\nimport { ReadFieldFunction } from '../core/types/common';\n\nexport interface WriteContext extends ReadMergeModifyContext {\n  readonly written: {\n    [dataId: string]: SelectionSetNode[];\n  };\n  readonly fragmentMap?: FragmentMap;\n  // General-purpose deep-merge function for use during writes.\n  merge<T>(existing: T, incoming: T): T;\n  // If true, merge functions will be called with undefined existing data.\n  overwrite: boolean;\n  incomingById: Map<string, {\n    storeObject: StoreObject;\n    mergeTree?: MergeTree;\n    fieldNodeSet: Set<FieldNode>;\n  }>;\n  // Directive metadata for @client and @defer. We could use a bitfield for this\n  // information to save some space, and use that bitfield number as the keys in\n  // the context.flavors Map.\n  clientOnly: boolean;\n  deferred: boolean;\n  flavors: Map<string, FlavorableWriteContext>;\n};\n\ntype FlavorableWriteContext = Pick<\n  WriteContext,\n  | \"clientOnly\"\n  | \"deferred\"\n  | \"flavors\"\n>;\n\n// Since there are only four possible combinations of context.clientOnly and\n// context.deferred values, we should need at most four \"flavors\" of any given\n// WriteContext. To avoid creating multiple copies of the same context, we cache\n// the contexts in the context.flavors Map (shared by all flavors) according to\n// their clientOnly and deferred values (always in that order).\nfunction getContextFlavor<TContext extends FlavorableWriteContext>(\n  context: TContext,\n  clientOnly: TContext[\"clientOnly\"],\n  deferred: TContext[\"deferred\"],\n): TContext {\n  const key = `${clientOnly}${deferred}`;\n  let flavored = context.flavors.get(key);\n  if (!flavored) {\n    context.flavors.set(key, flavored = (\n      context.clientOnly === clientOnly &&\n      context.deferred === deferred\n    ) ? context : {\n      ...context,\n      clientOnly,\n      deferred,\n    });\n  }\n  return flavored as TContext;\n}\n\ninterface ProcessSelectionSetOptions {\n  dataId?: string,\n  result: Record<string, any>;\n  selectionSet: SelectionSetNode;\n  context: WriteContext;\n  mergeTree: MergeTree;\n}\n\nexport class StoreWriter {\n  constructor(\n    public readonly cache: InMemoryCache,\n    private reader?: StoreReader,\n  ) {}\n\n  public writeToStore(store: NormalizedCache, {\n    query,\n    result,\n    dataId,\n    variables,\n    overwrite,\n  }: Cache.WriteOptions): Reference | undefined {\n    const operationDefinition = getOperationDefinition(query)!;\n    const merger = makeProcessedFieldsMerger();\n\n    variables = {\n      ...getDefaultValues(operationDefinition),\n      ...variables!,\n    };\n\n    const context: WriteContext = {\n      store,\n      written: Object.create(null),\n      merge<T>(existing: T, incoming: T) {\n        return merger.merge(existing, incoming) as T;\n      },\n      variables,\n      varString: canonicalStringify(variables),\n      fragmentMap: createFragmentMap(getFragmentDefinitions(query)),\n      overwrite: !!overwrite,\n      incomingById: new Map,\n      clientOnly: false,\n      deferred: false,\n      flavors: new Map,\n    };\n\n    const ref = this.processSelectionSet({\n      result: result || Object.create(null),\n      dataId,\n      selectionSet: operationDefinition.selectionSet,\n      mergeTree: { map: new Map },\n      context,\n    });\n\n    if (!isReference(ref)) {\n      throw new InvariantError(`Could not identify object ${JSON.stringify(result)}`);\n    }\n\n    // So far, the store has not been modified, so now it's time to process\n    // context.incomingById and merge those incoming fields into context.store.\n    context.incomingById.forEach(({ storeObject, mergeTree, fieldNodeSet }, dataId) => {\n      const entityRef = makeReference(dataId);\n\n      if (mergeTree && mergeTree.map.size) {\n        const applied = this.applyMerges(mergeTree, entityRef, storeObject, context);\n        if (isReference(applied)) {\n          // Assume References returned by applyMerges have already been merged\n          // into the store. See makeMergeObjectsFunction in policies.ts for an\n          // example of how this can happen.\n          return;\n        }\n        // Otherwise, applyMerges returned a StoreObject, whose fields we should\n        // merge into the store (see store.merge statement below).\n        storeObject = applied;\n      }\n\n      if (__DEV__ && !context.overwrite) {\n        const fieldsWithSelectionSets: Record<string, true> = Object.create(null);\n        fieldNodeSet.forEach(field => {\n          if (field.selectionSet) {\n            fieldsWithSelectionSets[field.name.value] = true;\n          }\n        });\n\n        const hasSelectionSet = (storeFieldName: string) =>\n          fieldsWithSelectionSets[\n            fieldNameFromStoreName(storeFieldName)\n          ] === true;\n\n        const hasMergeFunction = (storeFieldName: string) => {\n          const childTree = mergeTree && mergeTree.map.get(storeFieldName);\n          return Boolean(childTree && childTree.info && childTree.info.merge);\n        };\n\n        Object.keys(storeObject).forEach(storeFieldName => {\n          // If a merge function was defined for this field, trust that it\n          // did the right thing about (not) clobbering data. If the field\n          // has no selection set, it's a scalar field, so it doesn't need\n          // a merge function (even if it's an object, like JSON data).\n          if (hasSelectionSet(storeFieldName) &&\n              !hasMergeFunction(storeFieldName)) {\n            warnAboutDataLoss(\n              entityRef,\n              storeObject,\n              storeFieldName,\n              context.store,\n            );\n          }\n        });\n      }\n\n      store.merge(dataId, storeObject);\n    });\n\n    // Any IDs written explicitly to the cache will be retained as\n    // reachable root IDs for garbage collection purposes. Although this\n    // logic includes root IDs like ROOT_QUERY and ROOT_MUTATION, their\n    // retainment counts are effectively ignored because cache.gc() always\n    // includes them in its root ID set.\n    store.retain(ref.__ref);\n\n    return ref;\n  }\n\n  private processSelectionSet({\n    dataId,\n    result,\n    selectionSet,\n    context,\n    // This object allows processSelectionSet to report useful information\n    // to its callers without explicitly returning that information.\n    mergeTree,\n  }: ProcessSelectionSetOptions): StoreObject | Reference {\n    const { policies } = this.cache;\n\n    // This variable will be repeatedly updated using context.merge to\n    // accumulate all fields that need to be written into the store.\n    let incoming: StoreObject = Object.create(null);\n\n    // If typename was not passed in, infer it. Note that typename is\n    // always passed in for tricky-to-infer cases such as \"Query\" for\n    // ROOT_QUERY.\n    const typename: string | undefined =\n      (dataId && policies.rootTypenamesById[dataId]) ||\n      getTypenameFromResult(result, selectionSet, context.fragmentMap) ||\n      (dataId && context.store.get(dataId, \"__typename\") as string);\n\n    if (\"string\" === typeof typename) {\n      incoming.__typename = typename;\n    }\n\n    // This readField function will be passed as context.readField in the\n    // KeyFieldsContext object created within policies.identify (called below).\n    // In addition to reading from the existing context.store (thanks to the\n    // policies.readField(options, context) line at the very bottom), this\n    // version of readField can read from Reference objects that are currently\n    // pending in context.incomingById, which is important whenever keyFields\n    // need to be extracted from a child object that processSelectionSet has\n    // turned into a Reference.\n    const readField: ReadFieldFunction = function (this: void) {\n      const options = normalizeReadFieldOptions(\n        arguments,\n        incoming,\n        context.variables,\n      );\n\n      if (isReference(options.from)) {\n        const info = context.incomingById.get(options.from.__ref);\n        if (info) {\n          const result = policies.readField({\n            ...options,\n            from: info.storeObject\n          }, context);\n\n          if (result !== void 0) {\n            return result;\n          }\n        }\n      }\n\n      return policies.readField(options, context);\n    };\n\n    const fieldNodeSet = new Set<FieldNode>();\n\n    this.flattenFields(\n      selectionSet,\n      result,\n      // This WriteContext will be the default context value for fields returned\n      // by the flattenFields method, but some fields may be assigned a modified\n      // context, depending on the presence of @client and other directives.\n      context,\n      typename,\n    ).forEach((context, field) => {\n      const resultFieldKey = resultKeyNameFromField(field);\n      const value = result[resultFieldKey];\n\n      fieldNodeSet.add(field);\n\n      if (value !== void 0) {\n        const storeFieldName = policies.getStoreFieldName({\n          typename,\n          fieldName: field.name.value,\n          field,\n          variables: context.variables,\n        });\n\n        const childTree = getChildMergeTree(mergeTree, storeFieldName);\n\n        let incomingValue = this.processFieldValue(\n          value,\n          field,\n          // Reset context.clientOnly and context.deferred to their default\n          // values before processing nested selection sets.\n          field.selectionSet\n            ? getContextFlavor(context, false, false)\n            : context,\n          childTree,\n        );\n\n        // To determine if this field holds a child object with a merge function\n        // defined in its type policy (see PR #7070), we need to figure out the\n        // child object's __typename.\n        let childTypename: string | undefined;\n\n        // The field's value can be an object that has a __typename only if the\n        // field has a selection set. Otherwise incomingValue is scalar.\n        if (field.selectionSet &&\n            (isReference(incomingValue) ||\n             storeValueIsStoreObject(incomingValue))) {\n          childTypename = readField<string>(\"__typename\", incomingValue);\n        }\n\n        const merge = policies.getMergeFunction(\n          typename,\n          field.name.value,\n          childTypename,\n        );\n\n        if (merge) {\n          childTree.info = {\n            // TODO Check compatibility against any existing childTree.field?\n            field,\n            typename,\n            merge,\n          };\n        } else {\n          maybeRecycleChildMergeTree(mergeTree, storeFieldName);\n        }\n\n        incoming = context.merge(incoming, {\n          [storeFieldName]: incomingValue,\n        });\n\n      } else if (\n        __DEV__ &&\n        !context.clientOnly &&\n        !context.deferred &&\n        !addTypenameToDocument.added(field) &&\n        // If the field has a read function, it may be a synthetic field or\n        // provide a default value, so its absence from the written data should\n        // not be cause for alarm.\n        !policies.getReadFunction(typename, field.name.value)\n      ) {\n        invariant.error(`Missing field '${\n          resultKeyNameFromField(field)\n        }' while writing result ${\n          JSON.stringify(result, null, 2)\n        }`.substring(0, 1000));\n      }\n    });\n\n    // Identify the result object, even if dataId was already provided,\n    // since we always need keyObject below.\n    try {\n      const [id, keyObject] = policies.identify(result, {\n        typename,\n        selectionSet,\n        fragmentMap: context.fragmentMap,\n        storeObject: incoming,\n        readField,\n      });\n\n      // If dataId was not provided, fall back to the id just generated by\n      // policies.identify.\n      dataId = dataId || id;\n\n      // Write any key fields that were used during identification, even if\n      // they were not mentioned in the original query.\n      if (keyObject) {\n        // TODO Reverse the order of the arguments?\n        incoming = context.merge(incoming, keyObject);\n      }\n    } catch (e) {\n      // If dataId was provided, tolerate failure of policies.identify.\n      if (!dataId) throw e;\n    }\n\n    if (\"string\" === typeof dataId) {\n      const dataRef = makeReference(dataId);\n\n      // Avoid processing the same entity object using the same selection\n      // set more than once. We use an array instead of a Set since most\n      // entity IDs will be written using only one selection set, so the\n      // size of this array is likely to be very small, meaning indexOf is\n      // likely to be faster than Set.prototype.has.\n      const sets = context.written[dataId] || (context.written[dataId] = []);\n      if (sets.indexOf(selectionSet) >= 0) return dataRef;\n      sets.push(selectionSet);\n\n      // If we're about to write a result object into the store, but we\n      // happen to know that the exact same (===) result object would be\n      // returned if we were to reread the result with the same inputs,\n      // then we can skip the rest of the processSelectionSet work for\n      // this object, and immediately return a Reference to it.\n      if (this.reader && this.reader.isFresh(\n        result,\n        dataRef,\n        selectionSet,\n        context,\n      )) {\n        return dataRef;\n      }\n\n      const previous = context.incomingById.get(dataId);\n      if (previous) {\n        previous.storeObject = context.merge(previous.storeObject, incoming);\n        previous.mergeTree = mergeMergeTrees(previous.mergeTree, mergeTree);\n        fieldNodeSet.forEach(field => previous.fieldNodeSet.add(field));\n      } else {\n        context.incomingById.set(dataId, {\n          storeObject: incoming,\n          // Save a reference to mergeTree only if it is not empty, because\n          // empty MergeTrees may be recycled by maybeRecycleChildMergeTree and\n          // reused for entirely different parts of the result tree.\n          mergeTree: mergeTreeIsEmpty(mergeTree) ? void 0 : mergeTree,\n          fieldNodeSet,\n        });\n      }\n\n      return dataRef;\n    }\n\n    return incoming;\n  }\n\n  private processFieldValue(\n    value: any,\n    field: FieldNode,\n    context: WriteContext,\n    mergeTree: MergeTree,\n  ): StoreValue {\n    if (!field.selectionSet || value === null) {\n      // In development, we need to clone scalar values so that they can be\n      // safely frozen with maybeDeepFreeze in readFromStore.ts. In production,\n      // it's cheaper to store the scalar values directly in the cache.\n      return __DEV__ ? cloneDeep(value) : value;\n    }\n\n    if (isArray(value)) {\n      return value.map((item, i) => {\n        const value = this.processFieldValue(\n          item, field, context, getChildMergeTree(mergeTree, i));\n        maybeRecycleChildMergeTree(mergeTree, i);\n        return value;\n      });\n    }\n\n    return this.processSelectionSet({\n      result: value,\n      selectionSet: field.selectionSet,\n      context,\n      mergeTree,\n    });\n  }\n\n  // Implements https://spec.graphql.org/draft/#sec-Field-Collection, but with\n  // some additions for tracking @client and @defer directives.\n  private flattenFields<TContext extends Pick<\n    WriteContext,\n    | \"clientOnly\"\n    | \"deferred\"\n    | \"flavors\"\n    | \"fragmentMap\"\n    | \"variables\"\n  >>(\n    selectionSet: SelectionSetNode,\n    result: Record<string, any>,\n    context: TContext,\n    typename = getTypenameFromResult(result, selectionSet, context.fragmentMap),\n  ): Map<FieldNode, TContext> {\n    const fieldMap = new Map<FieldNode, TContext>();\n    const { policies } = this.cache;\n\n    const limitingTrie = new Trie<{\n      // Tracks whether (selectionSet, clientOnly, deferred) has been flattened\n      // before. The GraphQL specification only uses the fragment name for\n      // skipping previously visited fragments, but the top-level fragment\n      // selection set corresponds 1:1 with the fagment name (and is slightly\n      // easier too work with), and we need to consider clientOnly and deferred\n      // values as well, potentially revisiting selection sets that were\n      // previously visited with different inherited configurations of those\n      // directives.\n      visited?: boolean;\n    }>(false); // No need for WeakMap, since limitingTrie does not escape.\n\n    (function flatten(\n      this: void,\n      selectionSet: SelectionSetNode,\n      inheritedContext: TContext,\n    ) {\n      const visitedNode = limitingTrie.lookup(\n        selectionSet,\n        // Because we take inheritedClientOnly and inheritedDeferred into\n        // consideration here (in addition to selectionSet), it's possible for\n        // the same selection set to be flattened more than once, if it appears\n        // in the query with different @client and/or @directive configurations.\n        inheritedContext.clientOnly,\n        inheritedContext.deferred,\n      );\n      if (visitedNode.visited) return;\n      visitedNode.visited = true;\n\n      selectionSet.selections.forEach(selection => {\n        if (!shouldInclude(selection, context.variables)) return;\n\n        let { clientOnly, deferred } = inheritedContext;\n        if (\n          // Since the presence of @client or @defer on this field can only\n          // cause clientOnly or deferred to become true, we can skip the\n          // forEach loop if both clientOnly and deferred are already true.\n          !(clientOnly && deferred) &&\n          isNonEmptyArray(selection.directives)\n        ) {\n          selection.directives.forEach(dir => {\n            const name = dir.name.value;\n            if (name === \"client\") clientOnly = true;\n            if (name === \"defer\") {\n              const args = argumentsObjectFromField(dir, context.variables);\n              // The @defer directive takes an optional args.if boolean\n              // argument, similar to @include(if: boolean). Note that\n              // @defer(if: false) does not make context.deferred false, but\n              // instead behaves as if there was no @defer directive.\n              if (!args || (args as { if?: boolean }).if !== false) {\n                deferred = true;\n              }\n              // TODO In the future, we may want to record args.label using\n              // context.deferred, if a label is specified.\n            }\n          });\n        }\n\n        if (isField(selection)) {\n          const existing = fieldMap.get(selection);\n          if (existing) {\n            // If this field has been visited along another recursive path\n            // before, the final context should have clientOnly or deferred set\n            // to true only if *all* paths have the directive (hence the &&).\n            clientOnly = clientOnly && existing.clientOnly;\n            deferred = deferred && existing.deferred;\n          }\n\n          fieldMap.set(\n            selection,\n            getContextFlavor(context, clientOnly, deferred),\n          );\n\n        } else {\n          const fragment =\n            getFragmentFromSelection(selection, context.fragmentMap);\n\n          if (fragment &&\n              policies.fragmentMatches(\n                fragment, typename, result, context.variables)) {\n\n            flatten(\n              fragment.selectionSet,\n              getContextFlavor(context, clientOnly, deferred),\n            );\n          }\n        }\n      });\n    })(selectionSet, context);\n\n    return fieldMap;\n  }\n\n  private applyMerges<T extends StoreValue>(\n    mergeTree: MergeTree,\n    existing: StoreValue,\n    incoming: T,\n    context: WriteContext,\n    getStorageArgs?: Parameters<EntityStore[\"getStorage\"]>,\n  ): T | Reference {\n    if (mergeTree.map.size && !isReference(incoming)) {\n      const e: StoreObject | Reference | undefined = (\n        // Items in the same position in different arrays are not\n        // necessarily related to each other, so when incoming is an array\n        // we process its elements as if there was no existing data.\n        !isArray(incoming) &&\n        // Likewise, existing must be either a Reference or a StoreObject\n        // in order for its fields to be safe to merge with the fields of\n        // the incoming object.\n        (isReference(existing) || storeValueIsStoreObject(existing))\n      ) ? existing : void 0;\n\n      // This narrowing is implied by mergeTree.map.size > 0 and\n      // !isReference(incoming), though TypeScript understandably cannot\n      // hope to infer this type.\n      const i = incoming as StoreObject | StoreValue[];\n\n      // The options.storage objects provided to read and merge functions\n      // are derived from the identity of the parent object plus a\n      // sequence of storeFieldName strings/numbers identifying the nested\n      // field name path of each field value to be merged.\n      if (e && !getStorageArgs) {\n        getStorageArgs = [isReference(e) ? e.__ref : e];\n      }\n\n      // It's possible that applying merge functions to this subtree will\n      // not change the incoming data, so this variable tracks the fields\n      // that did change, so we can create a new incoming object when (and\n      // only when) at least one incoming field has changed. We use a Map\n      // to preserve the type of numeric keys.\n      let changedFields: Map<string | number, StoreValue> | undefined;\n\n      const getValue = (\n        from: typeof e | typeof i,\n        name: string | number,\n      ): StoreValue => {\n        return isArray(from)\n          ? (typeof name === \"number\" ? from[name] : void 0)\n          : context.store.getFieldValue(from, String(name))\n      };\n\n      mergeTree.map.forEach((childTree, storeFieldName) => {\n        const eVal = getValue(e, storeFieldName);\n        const iVal = getValue(i, storeFieldName);\n        // If we have no incoming data, leave any existing data untouched.\n        if (void 0 === iVal) return;\n        if (getStorageArgs) {\n          getStorageArgs.push(storeFieldName);\n        }\n        const aVal = this.applyMerges(\n          childTree,\n          eVal,\n          iVal,\n          context,\n          getStorageArgs,\n        );\n        if (aVal !== iVal) {\n          changedFields = changedFields || new Map;\n          changedFields.set(storeFieldName, aVal);\n        }\n        if (getStorageArgs) {\n          invariant(getStorageArgs.pop() === storeFieldName);\n        }\n      });\n\n      if (changedFields) {\n        // Shallow clone i so we can add changed fields to it.\n        incoming = (isArray(i) ? i.slice(0) : { ...i }) as T;\n        changedFields.forEach((value, name) => {\n          (incoming as any)[name] = value;\n        });\n      }\n    }\n\n    if (mergeTree.info) {\n      return this.cache.policies.runMergeFunction(\n        existing,\n        incoming,\n        mergeTree.info,\n        context,\n        getStorageArgs && context.store.getStorage(...getStorageArgs),\n      );\n    }\n\n    return incoming;\n  }\n}\n\nconst emptyMergeTreePool: MergeTree[] = [];\n\nfunction getChildMergeTree(\n  { map }: MergeTree,\n  name: string | number,\n): MergeTree {\n  if (!map.has(name)) {\n    map.set(name, emptyMergeTreePool.pop() || { map: new Map });\n  }\n  return map.get(name)!;\n}\n\nfunction mergeMergeTrees(\n  left: MergeTree | undefined,\n  right: MergeTree | undefined,\n): MergeTree {\n  if (left === right || !right || mergeTreeIsEmpty(right)) return left!;\n  if (!left || mergeTreeIsEmpty(left)) return right;\n\n  const info = left.info && right.info ? {\n    ...left.info,\n    ...right.info,\n  } : left.info || right.info;\n\n  const needToMergeMaps = left.map.size && right.map.size;\n  const map = needToMergeMaps ? new Map :\n    left.map.size ? left.map : right.map;\n\n  const merged = { info, map };\n\n  if (needToMergeMaps) {\n    const remainingRightKeys = new Set(right.map.keys());\n\n    left.map.forEach((leftTree, key) => {\n      merged.map.set(\n        key,\n        mergeMergeTrees(leftTree, right.map.get(key)),\n      );\n      remainingRightKeys.delete(key);\n    });\n\n    remainingRightKeys.forEach(key => {\n      merged.map.set(\n        key,\n        mergeMergeTrees(\n          right.map.get(key),\n          left.map.get(key),\n        ),\n      );\n    });\n  }\n\n  return merged;\n}\n\nfunction mergeTreeIsEmpty(tree: MergeTree | undefined): boolean {\n  return !tree || !(tree.info || tree.map.size);\n}\n\nfunction maybeRecycleChildMergeTree(\n  { map }: MergeTree,\n  name: string | number,\n) {\n  const childTree = map.get(name);\n  if (childTree && mergeTreeIsEmpty(childTree)) {\n    emptyMergeTreePool.push(childTree);\n    map.delete(name);\n  }\n}\n\nconst warnings = new Set<string>();\n\n// Note that this function is unused in production, and thus should be\n// pruned by any well-configured minifier.\nfunction warnAboutDataLoss(\n  existingRef: Reference,\n  incomingObj: StoreObject,\n  storeFieldName: string,\n  store: NormalizedCache,\n) {\n  const getChild = (objOrRef: StoreObject | Reference): StoreObject | false => {\n    const child = store.getFieldValue<StoreObject>(objOrRef, storeFieldName);\n    return typeof child === \"object\" && child;\n  };\n\n  const existing = getChild(existingRef);\n  if (!existing) return;\n\n  const incoming = getChild(incomingObj);\n  if (!incoming) return;\n\n  // It's always safe to replace a reference, since it refers to data\n  // safely stored elsewhere.\n  if (isReference(existing)) return;\n\n  // If the values are structurally equivalent, we do not need to worry\n  // about incoming replacing existing.\n  if (equal(existing, incoming)) return;\n\n  // If we're replacing every key of the existing object, then the\n  // existing data would be overwritten even if the objects were\n  // normalized, so warning would not be helpful here.\n  if (Object.keys(existing).every(\n    key => store.getFieldValue(incoming, key) !== void 0)) {\n    return;\n  }\n\n  const parentType =\n    store.getFieldValue<string>(existingRef, \"__typename\") ||\n    store.getFieldValue<string>(incomingObj, \"__typename\");\n  const fieldName = fieldNameFromStoreName(storeFieldName);\n  const typeDotName = `${parentType}.${fieldName}`;\n  // Avoid warning more than once for the same type and field name.\n  if (warnings.has(typeDotName)) return;\n  warnings.add(typeDotName);\n\n  const childTypenames: string[] = [];\n  // Arrays do not have __typename fields, and always need a custom merge\n  // function, even if their elements are normalized entities.\n  if (!isArray(existing) &&\n      !isArray(incoming)) {\n    [existing, incoming].forEach(child => {\n      const typename = store.getFieldValue(child, \"__typename\");\n      if (typeof typename === \"string\" &&\n          !childTypenames.includes(typename)) {\n        childTypenames.push(typename);\n      }\n    });\n  }\n\n  invariant.warn(\n`Cache data may be lost when replacing the ${fieldName} field of a ${parentType} object.\n\nTo address this problem (which is not a bug in Apollo Client), ${\n  childTypenames.length\n    ? \"either ensure all objects of type \" +\n        childTypenames.join(\" and \") + \" have an ID or a custom merge function, or \"\n    : \"\"\n}define a custom merge function for the ${\n  typeDotName\n} field, so InMemoryCache can safely merge these objects:\n\n  existing: ${JSON.stringify(existing).slice(0, 1000)}\n  incoming: ${JSON.stringify(incoming).slice(0, 1000)}\n\nFor more information about these options, please refer to the documentation:\n\n  * Ensuring entity objects have IDs: https://go.apollo.dev/c/generating-unique-identifiers\n  * Defining custom merge functions: https://go.apollo.dev/c/merging-non-normalized-objects\n`);\n}\n"]},"metadata":{},"sourceType":"module"}